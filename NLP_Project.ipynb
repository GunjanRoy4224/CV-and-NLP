{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyNz2kIjuKMHKgqcyUAyX+x8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GunjanRoy4224/CV-and-NLP/blob/main/NLP_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Track Capstone Project: Evaluation of Multilingual Models\n",
        " BERT (monolingual) with XLM-RoBERTa (multilingual)\n",
        "on sentiment classification across multiple languages.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Author: Gunjan Kumar\n",
        "\n",
        "Date: 4 November 2025"
      ],
      "metadata": {
        "id": "YKqrg-KHJ4sB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from datasets import load_dataset, Dataset\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"imports successful!\")\n",
        "print(f\"Using device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6O2jNXmKSlW",
        "outputId": "85907955-b8b6-49e3-ccb3-5674e3855312"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imports successful!\n",
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_multilingual_amazon_reviews():\n",
        "# Amazon multilingual reviews dataset\n",
        "    # Load datasets for multiple languages\n",
        "    languages = ['en', 'de', 'fr', 'es', 'ja']\n",
        "    language_names = {\n",
        "        'en': 'English',\n",
        "        'de': 'German',\n",
        "        'fr': 'French',\n",
        "        'es': 'Spanish',\n",
        "        'ja': 'Japanese'\n",
        "    }\n",
        "\n",
        "    datasets = {}\n",
        "\n",
        "    try:\n",
        "        # Load Amazon reviews for each language\n",
        "        for lang in languages:\n",
        "            print(f\"  Loading {language_names[lang]}...\")\n",
        "            ds = load_dataset(\"amazon_reviews_multi\", lang, split='train[:2000]')\n",
        "            # Map ratings to sentiment: 1-2=negative, 3=neutral, 4-5=positive\n",
        "            ds = ds.map(lambda x: {\n",
        "                'text': x['review_body'],\n",
        "                'label': 0 if x['stars'] <= 2 else (1 if x['stars'] == 3 else 2),\n",
        "                'language': lang\n",
        "            })\n",
        "            datasets[lang] = ds\n",
        "\n",
        "        print(f\"Successfully loaded {len(languages)} languages\")\n",
        "        return datasets, language_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "0MdeOnvHLmqP",
        "outputId": "69f8c474-09c8-43cb-df92-491765cbddcd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (ipython-input-632391921.py, line 29)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-632391921.py\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    return datasets, language_names\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    }
  ]
}